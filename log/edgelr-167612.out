Running SLURM prolog script on indigo60.cluster.local
===============================================================================
Job started on Sat  8 May 22:09:39 BST 2021
Job ID          : 167612
Job name        : edgelr
WorkDir         : /mainfs/home/jlc1n20/projects/cluster_gnn
Command         : /mainfs/home/jlc1n20/projects/cluster_gnn/scripts/sub_lr.sh
Partition       : gpu
Num hosts       : 1
Num cores       : 1
Num of tasks    : 1
Hosts allocated : indigo60
Job Output Follows ...
===============================================================================
  0%|          | 0/90000 [00:00<?, ?it/s]  0%|          | 1/90000 [00:00<18:41:06,  1.34it/s]  0%|          | 3/90000 [00:00<6:54:44,  3.62it/s]   0%|          | 4/90000 [00:01<5:47:53,  4.31it/s]  0%|          | 5/90000 [00:01<5:16:11,  4.74it/s]  0%|          | 6/90000 [00:01<4:35:39,  5.44it/s]  0%|          | 7/90000 [00:01<4:36:24,  5.43it/s]  0%|          | 8/90000 [00:01<4:15:31,  5.87it/s]  0%|          | 9/90000 [00:01<3:49:30,  6.54it/s]  0%|          | 10/90000 [00:02<4:03:41,  6.15it/s]  0%|          | 11/90000 [00:02<3:44:04,  6.69it/s]  0%|          | 12/90000 [00:02<4:10:45,  5.98it/s]  0%|          | 13/90000 [00:02<3:57:18,  6.32it/s]  0%|          | 14/90000 [00:02<3:42:39,  6.74it/s]  0%|          | 15/90000 [00:02<3:31:40,  7.08it/s]  0%|          | 16/90000 [00:02<3:42:24,  6.74it/s]  0%|          | 17/90000 [00:03<5:25:46,  4.60it/s]  0%|          | 19/90000 [00:03<3:51:19,  6.48it/s]  0%|          | 20/90000 [00:03<3:40:11,  6.81it/s]  0%|          | 21/90000 [00:03<3:37:09,  6.91it/s]  0%|          | 22/90000 [00:03<3:29:18,  7.16it/s]  0%|          | 24/90000 [00:04<2:49:44,  8.83it/s]  0%|          | 25/90000 [00:04<2:47:17,  8.96it/s]  0%|          | 26/90000 [00:04<3:03:56,  8.15it/s]  0%|          | 27/90000 [00:04<3:11:40,  7.82it/s]  0%|          | 28/90000 [00:04<3:32:45,  7.05it/s]  0%|          | 30/90000 [00:04<4:00:31,  6.23it/s]  0%|          | 31/90000 [00:05<3:52:26,  6.45it/s]  0%|          | 32/90000 [00:05<3:51:39,  6.47it/s]  0%|          | 33/90000 [00:05<4:05:23,  6.11it/s]  0%|          | 34/90000 [00:05<4:40:56,  5.34it/s]  0%|          | 36/90000 [00:05<3:16:41,  7.62it/s]  0%|          | 38/90000 [00:05<2:40:52,  9.32it/s]  0%|          | 40/90000 [00:06<2:30:06,  9.99it/s]  0%|          | 42/90000 [00:06<2:23:41, 10.43it/s]  0%|          | 44/90000 [00:06<2:54:08,  8.61it/s]  0%|          | 45/90000 [00:06<2:55:41,  8.53it/s]  0%|          | 46/90000 [00:06<3:10:24,  7.87it/s]  0%|          | 47/90000 [00:07<3:09:10,  7.92it/s]  0%|          | 48/90000 [00:07<3:58:25,  6.29it/s]
Epoch 0:
Traceback (most recent call last):
  File "/home/jlc1n20/projects/cluster_gnn/scripts/train_lr2.py", line 25, in <module>
    edge_pred = model(data)
  File "/scratch/jlc1n20/miniconda3/envs/PyG/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mainfs/home/jlc1n20/projects/cluster_gnn/src/cluster_gnn/models/gnn.py", line 72, in forward
    edge_attrs, node_attrs = self.conv6(node_attrs, data.edge_index, edge_attrs)
  File "/scratch/jlc1n20/miniconda3/envs/PyG/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mainfs/home/jlc1n20/projects/cluster_gnn/src/cluster_gnn/models/gnn.py", line 23, in forward
    return self.propagate(
  File "/scratch/jlc1n20/miniconda3/envs/PyG/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 237, in propagate
    out = self.message(**msg_kwargs)
  File "/mainfs/home/jlc1n20/projects/cluster_gnn/src/cluster_gnn/models/gnn.py", line 34, in message
    self.edge_embed = self.mlp_edge(recv_send)
  File "/scratch/jlc1n20/miniconda3/envs/PyG/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/scratch/jlc1n20/miniconda3/envs/PyG/lib/python3.8/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/scratch/jlc1n20/miniconda3/envs/PyG/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/scratch/jlc1n20/miniconda3/envs/PyG/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 94, in forward
    return F.linear(input, self.weight, self.bias)
  File "/scratch/jlc1n20/miniconda3/envs/PyG/lib/python3.8/site-packages/torch/nn/functional.py", line 1753, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 15.78 GiB total capacity; 12.49 GiB already allocated; 123.50 MiB free; 14.42 GiB reserved in total by PyTorch)
==============================================================================
Running epilogue script on indigo60.

Submit time  : 2021-05-08T22:09:39
Start time   : 2021-05-08T22:09:39
End time     : 2021-05-08T22:10:01
Elapsed time : 00:00:22 (Timelimit=1-00:00:00)

Job ID: 167612
Cluster: i5
User/Group: jlc1n20/fp
State: FAILED (exit code 1)
Cores: 1
CPU Utilized: 00:00:12
CPU Efficiency: 54.55% of 00:00:22 core-walltime
Job Wall-clock time: 00:00:22
Memory Utilized: 2.06 MB
Memory Efficiency: 0.01% of 40.00 GB

