#!/bin/bash

#---------------------- GETTING COMMAND LINE ARGUMENTS -----------------------#
# Set some default values:
CONDENV=base
SIMNAME=unset
INTERVAL=unset
OUTDIR=unset
TAG_MCPIDS=unset
OFFSET=0

usage() {
    echo "Usage: mkdset [OPTIONS]"
    echo "Description:
    Creates data pipeline for running MadGraph, processing the output,
    and formatting into HDF5 files for use in neural networks.
    NOTE: multiple int options must be given in quotation marks,
          separated with spaces."
    echo "Options:
    -c, --conda-env STRING          [optional, default: base]
        environment in which MadGraph will run
        NOTE: data extraction currently assumes jet-tools env exists
    -n, --sim-name STRING           [required]
        name of the MadGraph directory holding the sim data
        NOTE: this is currently assumed to be in /scratch/<uname>/data/
    -i, --interval INT(S)           [required, eg. 175 or '90 100']
        specifies number of runs, eg. 001_run, 002_run, ..., 010_run
        if one number provided, eg. -i 175, will produce runs 1 -> 175
        if two given, 1st is start, eg. -i '90 92' gives runs 90 -> 92
        if three given, 1st = start, 2nd = stride, 3rd = stop
    -o, --out-dir PATH              [optional, default: unset]
        the directory in which the final HDF5 files will be stored
        if unset, fragment HDF5 files will be left for later combining
    -t, --tag-mcpids MULTIPLE INTS  [required, eg. '1 2 3 4 5 21']
        MCPID / PDG codes specifying which jets should be tagged
    -z, --offset INT                [optional, default: 0]
        numbers the events from a different starting point
        eg. if another sim w/ two 5,000 evt runs exists, use '-z 10000'"
    exit 2
}

PARSEDARGS=$(getopt -a -n mkdset -o c:n:i:o:t: \
             --long conda-env:,sim-name:,interval:,out-dir:,tag-mcpids: \
             -- "$@")
VALARGS=$?
if [ "$VALARGS" != "0" ]; then
    usage
fi

eval set -- "$PARSEDARGS"
while :
do
    case "$1" in
        -c | --conda-env) CONDENV="$2"; shift 2 ;;
        -n | --sim-name) SIMNAME="$2"; shift 2 ;;
        -i | --interval) INTERVAL="$2"; shift 2 ;;
        -o | --out-dir) OUTDIR="$2"; shift 2 ;;
        -t | --tag-mcpids) TAG_MCPIDS="$2"; shift 2 ;;
        -z | --offset) OFFSET="$2"; shift 2 ;;
        # -- means the end of the arguments; drop this, and break out of the while loop
        --) shift; break ;;
        # If invalid options were passed, then getopt should have reported an error,
        # which we checked as VALARGS when getopt was called...
        *) echo "Unexpected option: $1 - this should not happen."
        usage ;;
    esac
done

reqok=1
required() {
    if [ 'unset' = ${2} ] ; then
        echo "${1} is required."
        reqok=0
    fi
}

required '-n/--sim-name' $SIMNAME
required '-i/--interval' $INTERVAL
required '-t/--tag-mcpids' $TAG_MCPIDS

if [ $reqok -eq 0 ] ; then
    usage
fi

#------------------------- STARTING THE DATA PIPELINE ------------------------#
datadir=/scratch/$USER/data
simdir=$datadir/$SIMNAME
evtdir=$simdir/Events

projdir=$(cd `dirname $0` && cd .. && pwd)

if [ ! -d $simdir ] ; then
    echo "Error: your simulation directory was not found at $simdir"
    exit 2
fi


for i in `echo $INTERVAL | xargs seq` ; do
    rundir=`printf "%03d" $i`_run

    # if directory already exists, replace it with empty one
    if [ -d $evtdir/$rundir ]; then
        rm -rf $evtdir/$rundir
    fi

    mkdir $evtdir/$rundir

    # submit data gen script, and store the job id
    jstring=`sbatch --job-name=$SIMNAME --dependency=singleton \
                    --output="$evtdir/$rundir/datagen.log" \
                    .slurm/genevts.sh $simdir $CONDENV $rundir`
    jid=`echo $jstring | awk '{print $NF}'`

    # once data gen has been successful, process and output hdf5
    gnum=$(( $i % 4 ))
    gname="con${SIMNAME}${gnum}"
    jstring=`sbatch --job-name=$gname --dependency=afterok:${jid},singleton \
                    --output="$evtdir/$rundir/convert.log" \
                    .slurm/extract.sh $projdir $simdir $rundir $TAG_MCPIDS \
                                      $OFFSET`
    jid=`echo $jstring | awk '{print $NF}'`
    if [ -z $mergedeps ] ; then
        mergedeps="afterok:$jid"
    else
        mergedeps="$mergedeps,afterok:$jid"
    fi
done

echo $mergedeps
# after all data has been converted, train / valid / test dsets
if [ ! 'unset' = $OUTDIR ] ; then
    sbatch --job-name='merge' --dependency=$mergedeps \
           .slurm/merge.sh $datadir $projdir $OUTDIR
fi
